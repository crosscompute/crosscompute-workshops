{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract a Table of Human Trafficking Incidents from a Table of USA DOJ Court Case Press Releases using spaCy\n",
    "\n",
    "We presented this [tool](https://crosscompute.com/t/xcRVUcyavDjewFXqvGXVrxSomTn3Ut2z) and [notebook](https://crosscompute.com/n/BhkK4AlpPD4Hmn8O0mbDtrH0q4HzphfN/-/extract-human-trafficking-incidents-from-court-cases-using-spacy) as part of our workshop on [Computational Approaches to Fight Human Trafficking](https://www.meetup.com/spatiotemporal-analysis-for-community-health-and-safety/events/244179401). Thanks to Aida Shoydokova for writing much of the original code.\n",
    "\n",
    "- The environment level must be set to **COMPUTATIONAL** in order for this code to run.\n",
    "- The memory level should be set to LARGE or higher to use spacy's higher accuracy models.\n",
    "- This code may take a long time to run. We recommend reserving an execution time of at least **10 minutes**, depending on the size of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrossCompute\n",
    "usa_doj_press_release_table_path = (\n",
    "    'human-trafficking-usa-doj-20171111-1730-sample-30.csv')\n",
    "keyword_prefix = 'traffick'\n",
    "category_text_path = 'human-trafficking-categories.txt'\n",
    "target_folder = '/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "\n",
    "environment_level = int(environ.get(\n",
    "    'CROSSCOMPUTE_ENVIRONMENT_LEVEL', 0))\n",
    "memory_level = int(environ.get(\n",
    "    'CROSSCOMPUTE_MEMORY_LEVEL'))\n",
    "\n",
    "if environment_level < 1:\n",
    "    print(\n",
    "        'environment_level.error = environment level must be set to '\n",
    "        'computational in order to use the spacy package because it '\n",
    "        'takes too long to install')\n",
    "\n",
    "if memory_level < 3:\n",
    "    print(\n",
    "        'memory_level.error = memory level should be set to large '\n",
    "        'or higher in order to use the en_core_web_lg spacy model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "if memory_level < 3:\n",
    "    spacy_model = 'en'\n",
    "else:\n",
    "    spacy_model = 'en_core_web_lg'\n",
    "    \n",
    "print('spacy_model = %s' % spacy_model)\n",
    "nlp = spacy.load(spacy_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "t = pd.read_csv(usa_doj_press_release_table_path)\n",
    "print('document_count = %s' % len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [x.lower() for x in open(\n",
    "    category_text_path).read().splitlines()]\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Documents Related to Human Trafficking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "PATTERN_KEYWORD = re.compile(r'human\\s+traffick', re.IGNORECASE)\n",
    "\n",
    "def has_right_topic(topic_names):\n",
    "    if pd.isnull(topic_names):\n",
    "        return False\n",
    "    for topic_name in topic_names.split(';'):\n",
    "        if PATTERN_KEYWORD.search(topic_name):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "t['has_right_topic'] = t['topic_names'].map(has_right_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of documents with the right topic\n",
    "print('matching_topic_document_count = %s' % t[\n",
    "    'has_right_topic'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_empty_topic_but_right_text(row):\n",
    "    topic_names = row['topic_names']\n",
    "    if not pd.isnull(topic_names):\n",
    "        return False\n",
    "    title = row['title']\n",
    "    if not pd.isnull(title) and PATTERN_KEYWORD.search(title):\n",
    "        return True\n",
    "    body = row['body']\n",
    "    if not pd.isnull(body) and PATTERN_KEYWORD.search(body):\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "t['has_empty_topic_but_right_text'] = t.apply(\n",
    "    has_empty_topic_but_right_text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of documents with empty topic but right text\n",
    "print('empty_topic_matching_text_document_count = %s' % t[\n",
    "    'has_empty_topic_but_right_text'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of human trafficking court cases\n",
    "selected_t = t[\n",
    "    t.has_right_topic | t.has_empty_topic_but_right_text].copy()\n",
    "print('human_trafficking_document_count = %s' % len(selected_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "NEWLINE_PATTERN = re.compile(r'\\n+', re.MULTILINE)\n",
    "\n",
    "def get_body_text(x):\n",
    "    if not hasattr(x, 'getText'):\n",
    "        x = BeautifulSoup(x, 'lxml')\n",
    "    # Extract text without tags\n",
    "    text = x.getText(separator=u'\\n').strip()\n",
    "    # Replace multiple newlines with a single newline\n",
    "    text = NEWLINE_PATTERN.sub('\\n', text)\n",
    "    return text\n",
    "\n",
    "selected_t['body_text'] = selected_t['body'].map(get_body_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def combine_matches(count_by_x):\n",
    "    'Combine first or last name counts with full name counts'\n",
    "    d = dict(count_by_x)\n",
    "    for x1, x2 in combinations(d.keys(), 2):\n",
    "        if x1 in x2:\n",
    "            abridged_x = x1\n",
    "            full_x = x2\n",
    "        elif x2 in x1:\n",
    "            abridged_x = x2\n",
    "            full_x = x1    \n",
    "        else:\n",
    "            continue\n",
    "        d[full_x] += d[abridged_x]\n",
    "        d[abridged_x] = 0\n",
    "    return d\n",
    "\n",
    "combine_matches({\n",
    "    'benjamin b wagner': 1,\n",
    "    'benjamin': 3,\n",
    "    'anthony w ishii': 2,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_count_table = pd.read_csv(\n",
    "    'names-usa.csv.xz', compression='xz', index_col=0)\n",
    "\n",
    "def get_gender(name):\n",
    "    if not name:\n",
    "        return\n",
    "    given_name = name.split()[0].lower()\n",
    "    try:\n",
    "        selected_table = name_count_table.loc[given_name]\n",
    "    except KeyError:\n",
    "        return\n",
    "    return selected_table.idxmax()\n",
    "\n",
    "get_gender('jay leno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_category_with_spacy(spacy_doc):\n",
    "    vote_by_category = defaultdict(int)\n",
    "    vote_weight = 1  # Count votes less if the term appears later\n",
    "    for chunk in spacy_doc.noun_chunks:\n",
    "        # Ignore chunks whose root does not include our keyword\n",
    "        if not chunk.root.text.lower().startswith(keyword_prefix):\n",
    "            continue\n",
    "        for x in categories:\n",
    "            if x in chunk.text.split():\n",
    "                vote_by_category[x] += vote_weight\n",
    "                vote_weight *= 0.9\n",
    "    if not vote_by_category:\n",
    "        return\n",
    "    return pd.Series(vote_by_category).idxmax()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def extract_information_with_spacy(row):\n",
    "    spacy_doc = nlp(row.body_text)\n",
    "    places, names = [], []\n",
    "    for entity in spacy_doc.ents:\n",
    "        label = entity.label_\n",
    "        x = entity.text\n",
    "        x = x.lower().replace('.', '').strip()\n",
    "        if len(x) < 2:\n",
    "            continue  # Skip single characters\n",
    "        if label == 'GPE':\n",
    "            places.append(x)\n",
    "        elif label == 'PERSON':\n",
    "            names.append(x)\n",
    "                \n",
    "    if places:\n",
    "        count_by_place = combine_matches(Counter(places))\n",
    "        place = pd.Series(count_by_place).idxmax()\n",
    "    else:\n",
    "        place = None\n",
    "        \n",
    "    if names:\n",
    "        count_by_name = combine_matches(Counter(names))\n",
    "        name = pd.Series(count_by_name).idxmax()\n",
    "    else:\n",
    "        name = None\n",
    "        \n",
    "    return pd.Series({\n",
    "        'place': place,\n",
    "        'name': name,\n",
    "        'gender': get_gender(name),\n",
    "        'category': get_category_with_spacy(spacy_doc),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_path = target_folder + '/incidents.csv'\n",
    "extracted_t = selected_t.apply(\n",
    "    extract_information_with_spacy, axis=1)\n",
    "extracted_t.to_csv(target_path, index = False)\n",
    "print('incident_table_path = %s' % target_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
